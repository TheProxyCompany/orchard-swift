# orchard-swift Critical Issues

Generated by sub-agent review on 2025-01-03. These issues represent fundamental implementation failures that must be fixed to achieve parity with orchard-py.

---

## The Verdict

**orchard-py (human-written):** ~640 lines in `client.py`. Handles batching correctly. Uses real Jinja2 templating. Has proper async/sync bridging. Tight, correct, production-ready.

**orchard-swift (agent-generated):** 346 lines in `OrchardClient.swift`, 165 lines in `ChatFormatter.swift`, 420 lines in `ModelRegistry.swift`, 359 lines in `InferenceEngine.swift`... **Hundreds more lines across the codebase that do less correctly.**

The agents shipped **functional-looking code** that would **fail at runtime**:
- ChatFormatter is hardcoded string concatenation, NOT template rendering
- Batching collects prompts but likely doesn't send them as one IPC message
- Model download just fails with "not supported" error
- Concurrency is disabled via `@unchecked Sendable` everywhere instead of designed correctly
- Profile lookup uses `#file` path manipulation that breaks when deployed

**The agents matched the API surface without understanding the implementation constraints.**

The ChatFormatter issue is particularly egregious. The agent looked at orchard-py's `ChatFormatter`, saw it loads a Jinja template and renders it, and wrote... string concatenation. The `reasoning` and `task` parameters are accepted but **completely ignored**. This means:
- Reasoning tokens won't be inserted
- Task-specific formatting won't happen
- Any model with non-trivial template logic produces wrong output

This is not "needs polish." This is "fundamentally broken."

---

## CRITICAL: ChatFormatter Doesn't Use Templates

**File:** `Sources/Orchard/Formatter/ChatFormatter.swift:64-83`

```swift
public func applyTemplate(
    _ conversation: [[String: Any]],
    addGenerationPrompt: Bool = true,
    reasoning: Bool = false,
    task: String? = nil
) -> String {
    var output = controlTokens.beginOfText

    for interaction in conversation {
        output += renderInteraction(interaction)
    }

    if addGenerationPrompt {
        if let agent = controlTokens.roles.agent {
            output += agent.roleStartTag + agent.roleName + agent.roleEndTag
        }
    }

    return output
}
```

**Problem:** This is hardcoded string concatenation. orchard-py loads `chat_template.jinja` and uses ACTUAL Jinja2 templating with conditionals, loops, and macros. This will produce WRONG OUTPUT for any model with non-trivial template logic (reasoning tokens, tool formatting, task-specific behavior).

**orchard-py reference:** `orchard/formatter/formatter.py:73-105`
```python
self.jinja_env = Environment(
    loader=FileSystemLoader(profile_dir), trim_blocks=True, lstrip_blocks=True
)
self.template = self.jinja_env.get_template("chat_template.jinja")
# ...
return self.template.render(**context)
```

**Fix required:**
1. Use a Swift Jinja2-compatible template engine (Stencil or similar)
2. Load and parse `chat_template.jinja` from profile directory
3. Pass full context including `reasoning`, `task`, `roles`, control tokens
4. Handle all template conditionals and loops

---

## CRITICAL: Batching Doesn't Batch

**File:** `Sources/Orchard/Client/OrchardClient.swift:40-93`

While `achatBatch` collects multiple `promptPayloads`, the underlying IPC call needs verification that it sends them as a single request.

**orchard-py reference:** `orchard/clients/client.py:496-639` - `_asubmit_request_batch` builds a single `prompts` list and sends ONE IPC message:
```python
request_bytes = _build_request_payload(
    request_id=request_id,
    model_id=model_id,
    model_path=info.model_path,
    request_type="generation",
    response_channel_id=response_channel_id,
    prompts=prompt_payloads,  # Multiple prompts, single message
)
await socket.asend(request_bytes)
```

**Fix required:**
1. Verify `ipcState.sendRequest` accepts and sends multiple prompts in one message
2. If not, fix IPC serialization to match orchard-py format
3. Response demultiplexing by `prompt_index` must work correctly

---

## CRITICAL: Model Download Not Supported

**File:** `Sources/Orchard/Model/ModelRegistry.swift:213-216`

```swift
// Model needs download - not supported in Swift yet
entry.state = .failed
entry.error = "Automatic model download not supported. Use: huggingface-cli download \(requestedModelId)"
return (.failed, canonicalId)
```

**Problem:** orchard-py uses `huggingface_hub.snapshot_download` to automatically download models. Swift just fails and tells users to download manually. This is not parity.

**orchard-py reference:** `orchard/app/model_registry.py:205-260`
```python
download_path = await asyncio.to_thread(
    snapshot_download,
    resolved.hf_repo or resolved.canonical_id,
    local_files_only=False,
    progress_callback=_progress_cb,
)
```

**Fix required:**
1. Implement HuggingFace Hub API calls for model download
2. Or use `huggingface-cli` as a subprocess
3. Support progress callbacks for download tracking

---

## HIGH: Concurrency Escape Hatches Everywhere

**Files:** Multiple

```swift
public final class OrchardClient: @unchecked Sendable { ... }
public final class ChatFormatter: @unchecked Sendable { ... }
public final class ModelRegistry: @unchecked Sendable { ... }
final class ModelEntry: @unchecked Sendable { ... }
nonisolated(unsafe) private static var atExitRegistered = false
```

**Problem:** These are Swift 6 concurrency escape hatches. The agent hit strict concurrency checking and said "mark it unsafe" instead of designing for thread safety.

**Fix required:**
1. Design proper actor isolation or Sendable conformance
2. Use actors where shared mutable state exists
3. Use proper synchronization primitives
4. Remove `@unchecked Sendable` annotations
5. Remove `nonisolated(unsafe)` - use proper atomic or actor

---

## HIGH: waitForEngineReady References Undefined Types

**File:** `Sources/Orchard/Engine/InferenceEngine.swift:261-299`

```swift
let tempSocket = try SubSocket()
// ...
} catch SocketError.timeout {
```

**Problem:** `SubSocket` and `SocketError` need to come from somewhere. If these are stubs or incomplete, engine startup won't work correctly.

**orchard-py reference:** `orchard/engine/multiprocess.py:199-270` uses pynng:
```python
temp_sub_socket = pynng.Sub0()
telemetry_topic = ipc_endpoints.EVENT_TOPIC_PREFIX + b"telemetry"
temp_sub_socket.subscribe(telemetry_topic)
temp_sub_socket.dial(ipc_endpoints.RESPONSE_URL, block=False)
```

**Fix required:**
1. Verify SubSocket implementation exists and works
2. Implement proper nng bindings for Swift
3. Match the telemetry subscription pattern from Python

---

## HIGH: Profile Directory Lookup is Fragile

**File:** `Sources/Orchard/Formatter/ChatFormatter.swift:119-142`

```swift
func getProfileDirectory(for modelType: String) -> URL {
    let currentFile = URL(fileURLWithPath: #file)
    let packageRoot = currentFile
        .deletingLastPathComponent() // Formatter
        .deletingLastPathComponent() // Orchard
        .deletingLastPathComponent() // Sources
        .deletingLastPathComponent() // orchard-swift

    let orchardPyProfiles = packageRoot
        .deletingLastPathComponent() // TheProxyCompany
        .appendingPathComponent("orchard-py/orchard/formatter/profiles")
```

**Problem:** Uses `#file` to navigate relative to source. This breaks when:
- Running from a different directory
- Deployed as a framework
- Running in a test context with different paths

**Fix required:**
1. Bundle profiles as Swift Package resources
2. Or use Bundle.module for resource lookup
3. Or configurable profile path via environment/config

---

## MEDIUM: renderInteraction is Oversimplified

**File:** `Sources/Orchard/Formatter/ChatFormatter.swift:87-114`

```swift
private func renderInteraction(_ interaction: [String: Any]) -> String {
    var result = ""
    let roleName = interaction["role"] as? String ?? "user"
    let role = controlTokens.roles.role(for: roleName)
    if let role = role {
        result += role.roleStartTag + role.roleName + role.roleEndTag
    }
    // Render content
    if let content = interaction["content"] {
        if let stringContent = content as? String {
            result += stringContent
        } else if let arrayContent = content as? [Any] {
            for item in arrayContent {
                if let renderable = item as? CustomStringConvertible {
                    result += renderable.description
                }
            }
        }
    }
    result += controlTokens.endOfSequence
    return result
}
```

**Problem:** This doesn't handle:
- Multimodal content (image placeholders)
- Tool calls
- System messages with special formatting
- Reasoning tokens based on `reasoning` flag

**orchard-py reference:** The Jinja templates handle all this complexity via template logic.

**Fix required:** Once proper templating is implemented, this method becomes unnecessary.

---

## MEDIUM: IPCState Implementation Needs Verification

The `IPCState` class is referenced but its implementation needs verification:
- Does `sendRequest` properly serialize batched prompts?
- Does it handle response demultiplexing?
- Does `registerQueue` work with AsyncStream correctly?

**orchard-py reference:** `orchard/app/ipc_dispatch.py`

---

## CRITICAL: Tests Are Useless

The Swift test files exist but suffer the same problems as Rust:

1. **Tests don't verify correctness** - they check "does it return something" not "does it work correctly"
2. **Tests would pass against broken implementations**
3. **Tests don't match orchard-py's test suite**

For batching, a test that just checks `responses.count == 2` passes even if the implementation loops and makes 2 separate IPC calls. The test doesn't verify:
- Single IPC message was sent
- `promptIndex` demultiplexing works
- Responses correlate to their prompts

For templating, tests don't verify:
- Reasoning tokens appear when `reasoning: true`
- Task-specific formatting happens when `task` is set
- Multimodal placeholders are handled correctly

**orchard-py tests go through the full HTTP stack and verify behavior:**
```python
response = await client.post(f"{server_url}/v1/chat/completions", json=request_payload)
assert len(choices) == 2
for index, choice in enumerate(choices):
    assert choice["index"] == index  # Verifies demultiplexing
```

**Fix required:**
1. **Port orchard-py tests exactly** - same prompts, same assertions
2. Tests must verify BEHAVIOR not just "doesn't crash"
3. For batching: verify single IPC call, verify promptIndex correlation
4. For templating: verify output contains expected tokens based on parameters
5. Actually RUN the tests

**Reference tests to port:**
- `orchard-py/tests/test_e2e_batching.py` - heterogeneous batching, index verification
- `orchard-py/tests/test_e2e_client.py` - client API tests
- `orchard-py/tests/test_e2e_multimodal.py` - image handling
- `orchard-py/tests/test_e2e_structured_generation.py` - JSON output
- `orchard-py/tests/test_e2e_stop_sequences.py` - stop sequence behavior
- `orchard-py/tests/test_e2e_determinism.py` - seed reproducibility
- `orchard-py/tests/test_e2e_capabilities.py` - control token resolution

---

## LOW: Error Handling is Generic

Many errors are just strings without structured information:

```swift
entry.error = error.localizedDescription
// ...
throw ModelRegistryError.loadFailed(error ?? "Model '\(canonicalId)' failed to load")
```

**orchard-py reference:** Uses specific exception types with detailed messages.

---

## Implementation Order

1. **Implement proper template rendering** - Core functionality, everything depends on correct prompts
2. **Fix concurrency model** - Remove escape hatches, use actors
3. **Implement model download** - Basic functionality gap
4. **Verify/fix IPC batching** - Performance critical
5. **Fix profile directory lookup** - Deployment readiness
6. **Verify SubSocket/IPC implementation** - Reliability

---

## Reference Files

When fixing, always compare against:
- `orchard-py/orchard/clients/client.py` - Client API and batching
- `orchard-py/orchard/engine/inference_engine.py` - Engine lifecycle
- `orchard-py/orchard/engine/multiprocess.py` - Process management, telemetry wait
- `orchard-py/orchard/app/model_registry.py` - Model state machine
- `orchard-py/orchard/formatter/formatter.py` - Template rendering (THIS IS KEY)
- `orchard-py/orchard/formatter/profiles/*/chat_template.jinja` - Actual templates
- `orchard-py/orchard/ipc/serialization.py` - IPC payload format
- `orchard-py/orchard/app/ipc_dispatch.py` - IPC state management

---

## Template Rendering Priority

The ChatFormatter issue is the most critical because wrong prompt formatting means:
- Models receive malformed input
- Reasoning tokens aren't inserted
- Tool calls aren't formatted correctly
- System prompts aren't handled correctly

This is not "cosmetic" - it's "produces wrong output."

Swift template options to investigate:
1. [Stencil](https://github.com/stencilproject/Stencil) - Jinja2-like for Swift
2. Custom parser for the specific templates we use
3. Call Python subprocess for template rendering (last resort)
